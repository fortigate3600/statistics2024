<!DOCTYPE html>
<html lang="it">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Breach</title>
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <div class="container">
      <a href="index.html">home</a>
      <div class="sopra">
        <h1 id="welcomeMessage">SDE simulating the Wiener process</h1>
        <div>
          <div id="controls">
            <button onclick="runSimulation()">Run</button>
            <button onclick="clearCanvas()">Clear</button>
            <label for="steps">Steps:</label>
            <input type="number" id="steps" value="100" min="10" max="1000" />
            <label for="mu"> Mu (Drift):</label>
            <input type="number" id="mu" value="0.1" step="0.01" />
            <label for="sigma">Sigma (Diffusion):</label>
            <input type="number" id="sigma" value="0.2" step="0.01" />
          </div>
        </div>
      </div>
      <div class="canvasdiv">
        <canvas id="chart" width="1000" height="550"></canvas>
        <div id="numbers"></div>
      </div>
    </div>

    <div class="containerimg">
      <p>
        Per visionare il codice, andare al link della
        <a href="https://github.com/fortigate3600/statistics2024">repository</a>
        di github, specificatamente il javascript di questa pagina si trova
        <a
          href="https://github.com/fortigate3600/statistics2024/blob/main/script5.js"
          >qui</a
        >
      </p>
    </div>

    <div>
      <header>
        <h1>Statistical Independence</h1>
      </header>
      <main>
        <section>
          <p>
            L’indipendenza statistica tra due eventi A e B in teoria della
            probabilità significa che il verificarsi dell’evento A non influenza
            in alcun modo la probabilità del verificarsi dell’evento B e
            viceversa. Formalmente, si dice che due eventi sono indipendenti se
            la probabilità della loro intersezione è il prodotto delle
            probabilità individuali: 𝑃 ( 𝐴 ∩ 𝐵 ) = 𝑃 ( 𝐴 ) ⋅ 𝑃 ( 𝐵 ). Questa
            relazione implica che conoscere l’informazione sull’esito di uno dei
            due eventi non fornisce alcuna informazione sull’altro evento. Un
            esempio comune per illustrare l’indipendenza statistica è il lancio
            di una moneta e il lancio di un dado. L’esito del lancio della
            moneta (ad esempio, ottenere testa o croce) è indipendente
            dall’esito del lancio del dado (ad esempio, ottenere un 4). In altre
            parole, la probabilità di ottenere testa con la moneta non è
            influenzata dal risultato del dado e viceversa, quindi i due eventi
            sono indipendenti. In termini più generali, questa definizione si
            estende anche a variabili casuali, dove due variabili casuali 𝑋 e 𝑌
            sono indipendenti se la distribuzione congiunta 𝑃 ( 𝑋 , 𝑌 ) P(X,Y) è
            il prodotto delle distribuzioni marginali, ovvero: 𝑃 ( 𝑋 = 𝑥 , 𝑌 = 𝑦
            ) = 𝑃 ( 𝑋 = 𝑥 ) ⋅ 𝑃 ( 𝑌 = 𝑦 ) L’indipendenza statistica è
            fondamentale in probabilità e statistica perché consente di
            semplificare calcoli e modelli, rendendo possibile analizzare
            sistemi complessi suddividendoli in componenti indipendenti.
          </p>
        </section>
      </main>
    </div>
    <script src="script5.js"></script>
  </body>
</html>
