<!DOCTYPE html>
<html lang="it">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Breach</title>
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <div class="container">
      <a href="index.html">home</a>
      <div class="sopra">
        <h1 id="welcomeMessage">SDE simulating the Wiener process</h1>
        <div>
          <div id="controls">
            <button onclick="runSimulation()">Run</button>
            <button onclick="clearCanvas()">Clear</button>
            <label for="steps">Steps:</label>
            <input type="number" id="steps" value="100" min="10" max="1000" />
            <label for="mu"> Mu (Drift):</label>
            <input type="number" id="mu" value="0.1" step="0.01" />
            <label for="sigma">Sigma (Diffusion):</label>
            <input type="number" id="sigma" value="0.2" step="0.01" />
          </div>
        </div>
      </div>
      <div class="canvasdiv">
        <canvas id="chart" width="1000" height="550"></canvas>
        <div id="numbers"></div>
      </div>
    </div>

    <div class="containerimg">
      <p>
        Per visionare il codice, andare al link della
        <a href="https://github.com/fortigate3600/statistics2024">repository</a>
        di github, specificatamente il javascript di questa pagina si trova
        <a
          href="https://github.com/fortigate3600/statistics2024/blob/main/script5.js"
          >qui</a
        >
      </p>
    </div>

    <div>
      <header>
        <h1>Statistical Independence</h1>
      </header>
      <main>
        <section>
          <p>
            Lâ€™indipendenza statistica tra due eventi A e B in teoria della
            probabilitÃ  significa che il verificarsi dellâ€™evento A non influenza
            in alcun modo la probabilitÃ  del verificarsi dellâ€™evento B e
            viceversa. Formalmente, si dice che due eventi sono indipendenti se
            la probabilitÃ  della loro intersezione Ã¨ il prodotto delle
            probabilitÃ  individuali: ğ‘ƒ ( ğ´ âˆ© ğµ ) = ğ‘ƒ ( ğ´ ) â‹… ğ‘ƒ ( ğµ ). Questa
            relazione implica che conoscere lâ€™informazione sullâ€™esito di uno dei
            due eventi non fornisce alcuna informazione sullâ€™altro evento. Un
            esempio comune per illustrare lâ€™indipendenza statistica Ã¨ il lancio
            di una moneta e il lancio di un dado. Lâ€™esito del lancio della
            moneta (ad esempio, ottenere testa o croce) Ã¨ indipendente
            dallâ€™esito del lancio del dado (ad esempio, ottenere un 4). In altre
            parole, la probabilitÃ  di ottenere testa con la moneta non Ã¨
            influenzata dal risultato del dado e viceversa, quindi i due eventi
            sono indipendenti. In termini piÃ¹ generali, questa definizione si
            estende anche a variabili casuali, dove due variabili casuali ğ‘‹ e ğ‘Œ
            sono indipendenti se la distribuzione congiunta ğ‘ƒ ( ğ‘‹ , ğ‘Œ ) P(X,Y) Ã¨
            il prodotto delle distribuzioni marginali, ovvero: ğ‘ƒ ( ğ‘‹ = ğ‘¥ , ğ‘Œ = ğ‘¦
            ) = ğ‘ƒ ( ğ‘‹ = ğ‘¥ ) â‹… ğ‘ƒ ( ğ‘Œ = ğ‘¦ ) Lâ€™indipendenza statistica Ã¨
            fondamentale in probabilitÃ  e statistica perchÃ© consente di
            semplificare calcoli e modelli, rendendo possibile analizzare
            sistemi complessi suddividendoli in componenti indipendenti.
          </p>
        </section>
      </main>
    </div>
    <script src="script5.js"></script>
  </body>
</html>
